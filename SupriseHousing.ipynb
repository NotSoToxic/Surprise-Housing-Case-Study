{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement :\n",
    "A US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them at a higher price. The company wants to know\n",
    "\n",
    "- Which variables are significant in predicting the price of a house, and\n",
    "- How well those variables describe the price of a house.\n",
    "Based on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the American market.\n",
    "\n",
    "### Business Goal :\n",
    "- Build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\n",
    "- Determine the optimal value of lambda for ridge and lasso regression.\n",
    "- This model will then be used by the management to understand how exactly the prices vary with the variables\n",
    "- They can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns.\n",
    "- The model will be a good way for the management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe([0.25,0.50,0.75,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chekcing the percentage of Null values in all the columns\n",
    "print('Percentage of Missing Values in each column is as follows:')\n",
    "print(round(df.isnull().sum()/len(df.index)*100,2).sort_values(ascending=False)[ round(df.isnull().sum()/len(df.index),2) > 0 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18 features have missing values, out of which 5 features have more than 45% missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking if NaN Values have any impact on the Sale Price or not\n",
    "nan_col = []\n",
    "for i in df.columns:\n",
    "    if df[i].isnull().sum() > 0:\n",
    "        nan_col.append(i)\n",
    "df_copy = df.copy()    \n",
    "fig,axs= plt.subplots(7,3,figsize=(20,50),squeeze=True)\n",
    "for i,ax in zip(nan_col,axs.flatten()):    \n",
    "    df_copy[i] = np.where(df_copy[i].isnull(), 'Null Values', 'Non-Null Values') \n",
    "    df_copy.groupby(i)['SalePrice'].median().plot.bar(color = list('gr'),rot=0,ax=ax,subplots=True)\n",
    "axs[6,1].set_axis_off()    \n",
    "axs[6,2].set_axis_off() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NaN values have some impact on the Sale Price. We will handle the missing values in the feature engineering section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of numerical features and the number of categorical features\n",
    "num_col = []\n",
    "cat_col = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtypes != 'O':\n",
    "        num_col.append(i)\n",
    "    else:\n",
    "        cat_col.append(i)\n",
    "print('There are', len(num_col) ,'numerical features in the dataset')\n",
    "print('There are', len(cat_col), 'categorical features in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chekcing if the median price changes with the year sold\n",
    "df['YrSold'] = df['YrSold'].astype('int')\n",
    "df.groupby('YrSold')['SalePrice'].median().plot()\n",
    "plt.xlabel('Year Sold')\n",
    "plt.ylabel('Median House Price')\n",
    "plt.title(\"House Price vs YearSold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the average proce decreases after 2007 and after the 2008 housing bubble crash, the house prices dropped significantly. Thus the year in which the house was sold has a considerable effect on the sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the Year Features from the Dataset and then checking how the price varies with respect to the age of the estate\n",
    "yr_cols = []\n",
    "for i in df.columns:\n",
    "    if 'Yr' in i or 'Year' in i or 'year' in i or 'yr' in i:\n",
    "        yr_cols.append(i)\n",
    "print('List of features with Year are:')\n",
    "print(yr_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the Age of the Building / Renovated Building / Garage with the Sold Price\n",
    "for feature in yr_cols:\n",
    "    if feature!='YrSold':\n",
    "        data=df.copy()\n",
    "        data[feature]=data['YrSold']-data[feature]\n",
    "        plt.scatter(data[feature],data['SalePrice'])\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('SalePrice')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like that the new properties are costlier than the old properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping ID Columns from dataset since it is useless in the prediction usecase\n",
    "df.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualising numerical predictor variables with Target Variables\n",
    "df_num = df.select_dtypes(include=['int64','float64'])\n",
    "fig,axs= plt.subplots(12,3,figsize=(20,80))\n",
    "for i,ax in zip(df_num.columns,axs.flatten()):\n",
    "    sns.scatterplot(x=i, y='SalePrice', hue='SalePrice',data=df_num,ax=ax,palette='icefire')\n",
    "    plt.xlabel(i,fontsize=12)\n",
    "    plt.ylabel('SalePrice',fontsize=12)\n",
    "    ax.set_title('SalePrice'+' VS '+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from the above plot:-\n",
    "- New properties are costlier than older properties. \n",
    "- GRLiving Area has a direct corelation with the proce of the property.\n",
    "- Total basement area, which is linearly related with the total living area, also is directly proportional to the price of the property.\n",
    "- Month sold has no effect on the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting Categorical Features with Sale Price\n",
    "def facetgrid_boxplot(x, y, **kwargs):\n",
    "    sns.boxplot(x=x, y=y)\n",
    "    x=plt.xticks(rotation=90)\n",
    "    \n",
    "categorical = df.select_dtypes(exclude=['int64','float64'])\n",
    "f = pd.melt(df, id_vars=['SalePrice'], value_vars=sorted(df[categorical.columns]))\n",
    "g = sns.FacetGrid(f, col=\"variable\", col_wrap=3, sharex=False, sharey=False, size=5)\n",
    "g = g.map(facetgrid_boxplot, \"value\", \"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few outliers which we handle in the feature engineering section by capping them to a lower percentile.\n",
    "From the above box plots we see that:-\n",
    "- Paved alleys properties demand a higher price.\n",
    "- Houses where the basement quality is good and excellent are sold at higher prices compared to others.\n",
    "- Houses with good and excelent garages are sold at higher prices.\n",
    "- Houses with good quality kitchens also impact the price in a postive way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the corelation\n",
    "plt.subplots(figsize = (25,20))\n",
    "#Plotting heatmap of numerical features\n",
    "sns.heatmap(round(df_num.corr(),2), cmap='coolwarm' , annot=True, center = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are highly correlated features. We will remove the highly corelated attributes after a few steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new Column to determine the age of the property\n",
    "df['age']=df['YrSold']-df['YearBuilt']\n",
    "df['garage_age'] = df['YrSold'] - df['GarageYrBlt']\n",
    "df['remodel_age'] = df['YrSold'] - df['YearRemodAdd']\n",
    "\n",
    "df.drop('GarageYrBlt',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert some Numerical Column to String columns since they are categorical variables. \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Year to String since they are categorical features and should not be treated as numerical features\n",
    "df[['MSSubClass']] = df[['MSSubClass']].astype(str) \n",
    "df['YrSold'] = df['YrSold'].astype(str)\n",
    "df['MoSold'] = df['MoSold'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values\n",
    "Instead of dropping rows or columns, we impute the NaN values with None, Default or similar values, since by intuion it is assumed that when a certain feature is missing in that property, it is left blank during data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of columns with Null Values again\n",
    "print(round(df.isnull().sum()/len(df.index)*100,2).sort_values(ascending=False)[ round(df.isnull().sum()/len(df.index),2) > 0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the Data Description\n",
    "#NA = No Pool for PoolQC\n",
    "df['PoolQC'] = df['PoolQC'].fillna('None')\n",
    "#NA = No Misc Feature for MiscFeature\n",
    "df['MiscFeature'] = df['MiscFeature'].fillna('None')\n",
    "#NA = No Alley\n",
    "df['Alley'] = df['Alley'].fillna('None')\n",
    "#NA = No Fireplace for FireplaceQu\n",
    "df['FireplaceQu'] = df['FireplaceQu'].fillna('None')\n",
    "#NA = No Fence\n",
    "df['Fence'] = df['Fence'].fillna('None')\n",
    "#NA = No Fireplace\n",
    "df['FireplaceQu'] = df['FireplaceQu'].fillna('None')\n",
    "#NA = No Garage\n",
    "df['GarageCond'] = df['GarageCond'].fillna('None')\n",
    "df['GarageType'] = df['GarageType'].fillna('None')\n",
    "df['GarageFinish'] = df['GarageFinish'].fillna('None')\n",
    "df['GarageQual'] = df['GarageQual'].fillna('None')\n",
    "df['garage_age'] = df['GarageQual'].fillna(0)   #No Garage No Age\n",
    "#NA = No Basement\n",
    "df['BsmtExposure'] = df['BsmtExposure'].fillna('None')\n",
    "df['BsmtFinType2'] = df['BsmtFinType2'].fillna('None')\n",
    "df['BsmtCond'] = df['BsmtCond'].fillna('None')\n",
    "df['BsmtQual'] = df['BsmtQual'].fillna('None')\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].fillna('None')\n",
    "#NA = No Masonery Area\n",
    "df['MasVnrType'] = df['MasVnrType'].fillna('None')\n",
    "df['MasVnrArea'] = df['MasVnrArea'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of columns with Null Values again\n",
    "print(round(df.isnull().sum()/len(df.index)*100,2).sort_values(ascending=False)[ round(df.isnull().sum()/len(df.index),2) > 0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LotFrontage : Replacing Null value with the median of the neighbourhood\n",
    "df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isnull().sum()/len(df.index)*100,5).sort_values(ascending=False)[ round(df.isnull().sum()/len(df.index),5) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the Electrical 0.06% rows with the mode\n",
    "df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isnull().sum()/len(df.index)*100,5).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the missing values have been taken care of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Utilities'].value_counts())\n",
    "print(df['Street'].value_counts())\n",
    "print(df['PoolQC'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns have above 99% same values, thus it does not play any part on predicting the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to remove redundant features\n",
    "def redundant_feature(df):\n",
    "    redundant = []\n",
    "    for i in df.columns:\n",
    "        counts = df[i].value_counts()\n",
    "        count_max = counts.iloc[0]\n",
    "        if count_max / len(df) * 100 > 99:\n",
    "            redundant.append(i)\n",
    "    redundant = list(redundant)\n",
    "    return redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_features = redundant_feature(df)\n",
    "redundant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping these features since they have more than 99% of a single category and thus play no part in the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(redundant_features,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers to make the model more robust\n",
    "# From EDA we see that Living Area, Garage Area, Basement Area and Lot Area. Removing outliers from these. Other outliers will be handled \n",
    "# during power transform\n",
    "def drop_outliers(x):\n",
    "    list = []\n",
    "    outl_col = ['GrLivArea','GarageArea','TotalBsmtSF','LotArea']\n",
    "    for col in outl_col:\n",
    "        Q1 = x[col].quantile(.25)\n",
    "        Q3 = x[col].quantile(.99)\n",
    "        IQR = Q3-Q1\n",
    "        x =  x[(x[col] >= (Q1-(1.5*IQR))) & (x[col] <= (Q3+(1.5*IQR)))] \n",
    "    return x  \n",
    "df = drop_outliers(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 outliers have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating some new features based on the existing features\n",
    "#Vintage house with remodified version of it plays a important role in prediction(i.e. high price )\n",
    "df['YrBltAndRemod']=df['YearBuilt']+df['YearRemodAdd']\n",
    "#Overall area for all floors and basement plays an important role, hence creating total area in square foot column\n",
    "df['Total_sqr_footage'] = (df['BsmtFinSF1'] + df['BsmtFinSF2'] + df['1stFlrSF'] + df['2ndFlrSF'])\n",
    "# Creating derived column for total number of bathrooms column\n",
    "df['Total_Bathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) + df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))\n",
    "#Creating derived column for total porch area \n",
    "df['Total_porch_sf'] = (df['OpenPorchSF'] + df['3SsnPorch'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dummy Variables for Categorical Columns\n",
    "num_col=[]\n",
    "cat_col=[]\n",
    "for i in df.columns:\n",
    "    if df[i].dtypes != 'O':\n",
    "        num_col.append(i)\n",
    "    else:\n",
    "        cat_col.append(i)\n",
    "df_dummy= pd.get_dummies(df[cat_col])   \n",
    "df=pd.concat([df,df_dummy],axis=1)\n",
    "df= df.drop(cat_col,axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('SalePrice',axis=1)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking co-related features\n",
    "corr = X.corr()\n",
    "corr1 = corr[abs(corr)>=.6]\n",
    "corr2 =  corr.where(~np.tril(np.ones(corr.shape)).astype(np.bool))  #To remove repetition and 1 correlations\n",
    "corr_result = corr2.stack()\n",
    "print(corr_result[(abs(corr_result) > 0.6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['OverallQual','YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF',\n",
    "        '1stFlrSF','2ndFlrSF','GrLivArea','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','Fireplaces','GarageCars',\n",
    "        'WoodDeckSF','YrBltAndRemod','Total_Bathrooms','MSSubClass_120','MSSubClass_160','MSSubClass_190','MSSubClass_20',\n",
    "        'MSSubClass_45','MSSubClass_50','MSSubClass_60','MSSubClass_75','MSSubClass_80','MSSubClass_85','MSSubClass_90',\n",
    "        'MSZoning_FV','MSZoning_RL','Alley_Grvl','Alley_None','LotShape_IR1','LandContour_Bnk','LotConfig_Corner',\n",
    "        'LandSlope_Gtl','Neighborhood_NPkVill','Condition1_Feedr','Condition2_Feedr','Condition2_RRAe','BldgType_1Fam',\n",
    "        'HouseStyle_1Story','RoofStyle_Flat','RoofStyle_Gable','RoofMatl_CompShg','Exterior2nd_AsbShng','Exterior2nd_BrkFace',\n",
    "        'Exterior2nd_CBlock','Exterior2nd_CmentBd','Exterior2nd_HdBoard','Exterior2nd_MetalSd','Exterior2nd_Plywood',\n",
    "        'Exterior2nd_Stucco','Exterior2nd_VinylSd','Exterior2nd_Wd Sdng','MasVnrType_None','ExterQual_Gd','ExterQual_TA',\n",
    "        'ExterCond_Gd','Foundation_CBlock','Foundation_Slab','BsmtQual_Gd','BsmtQual_None','BsmtCond_Gd','BsmtCond_None',\n",
    "        'BsmtCond_Po','BsmtExposure_None','BsmtFinType1_None','Heating_GasA','HeatingQC_Ex','CentralAir_N','Electrical_FuseA',\n",
    "        'KitchenQual_Gd','GarageType_Attchd','GarageType_None','GarageFinish_None','GarageQual_Ex','GarageQual_Fa',\n",
    "        'GarageQual_Gd','GarageQual_None','GarageQual_Po','GarageQual_TA','GarageCond_Ex','GarageCond_None','GarageCond_Po',\n",
    "        'GarageCond_TA','PavedDrive_N','Fence_None','MiscFeature_None','SaleType_New','SaleType_WD','SaleCondition_Normal',\n",
    "        'Foundation_PConc','MiscFeature_Gar2','Foundation_PConc','garage_age_None'],\n",
    "         axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chekcing the shape after dropping all co-related columns\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of Target Variable\n",
    "sns.distplot(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data is right-skewed. Tus we transform it to make it more gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the Target feature to make the data gaussian\n",
    "pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "y_train = pt.fit_transform(y_train.to_frame())\n",
    "y_test = pt.transform(y_test.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is now transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using a Minmax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = DataFrame(X_train)\n",
    "X_train.columns = X.columns\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = DataFrame(X_test)\n",
    "X_test.columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "ridge = Ridge()\n",
    "\n",
    "# Using RFE to find top 300 variables\n",
    "rfe = RFE(estimator=Ridge(), n_features_to_select=300)\n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "col = X_train.columns[rfe.support_]\n",
    "X_train_rfe = X_train[col]\n",
    "X_test_rfe = X_test[col]\n",
    "\n",
    "# cross validation\n",
    "folds = 11\n",
    "model_cv = GridSearchCV(estimator = ridge, param_grid = params, scoring= 'r2', cv = folds, return_train_score=True, verbose = 1)            \n",
    "model_cv.fit(X_train_rfe, y_train) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results = cv_results[cv_results['param_alpha']<=30]\n",
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title(\"R2 Score and Alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper right')\n",
    "plt.xticks(np.arange(0,30,5))\n",
    "plt.show()\n",
    "\n",
    "alpha = cv_results['param_alpha'].loc[cv_results['mean_test_score'].idxmax()]\n",
    "print('The optimum alpha is',alpha)\n",
    "ridge_final = Ridge(alpha=alpha)\n",
    "ridge_final.fit(X_train_rfe,y_train)\n",
    "ridge_coef = ridge_final.coef_\n",
    "y_test_pred = ridge_final.predict(X_test_rfe)\n",
    "print('The R2 Score of the model on the test dataset for optimum alpha is',r2_score(y_test, y_test_pred))\n",
    "print('The MSE of the model on the test dataset for optimum alpha is', mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chekcing the VIF\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_rfe.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "high_vif = vif[vif['VIF']>10]\n",
    "high_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping cols with high VIF\n",
    "X_train_rfe2 = X_train_rfe.drop(high_vif.Features,axis=1)\n",
    "X_test_rfe2 = X_test_rfe.drop(high_vif.Features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the columns which do not suffer from multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the second Ridge Model\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "ridge = Ridge(random_state=100)\n",
    "\n",
    "# cross validation\n",
    "folds = 11\n",
    "model_cv = GridSearchCV(estimator = ridge, param_grid = params, scoring= 'r2', cv = folds, return_train_score=True, verbose = 1)            \n",
    "model_cv.fit(X_train_rfe2, y_train) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results = cv_results[cv_results['param_alpha']<=30]\n",
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title(\"R2 Score and Alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper right')\n",
    "plt.xticks(np.arange(0,30,5))\n",
    "plt.show()\n",
    "\n",
    "alpha = cv_results['param_alpha'].loc[cv_results['mean_test_score'].idxmax()]\n",
    "print('The optimum alpha is',alpha)\n",
    "ridge_final2 = Ridge(alpha=alpha,random_state=100)\n",
    "ridge_final2.fit(X_train_rfe2,y_train)\n",
    "ridge_coef2 = ridge_final2.coef_\n",
    "y_test_pred = ridge_final2.predict(X_test_rfe2)\n",
    "print('The R2 Score of the model on the test dataset for optimum alpha is',r2_score(y_test, y_test_pred))\n",
    "print('The MSE of the model on the test dataset for optimum alpha is', mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaing the co-efficients of the model\n",
    "ridge_coeff2 = pd.DataFrame(np.atleast_2d(ridge_coef2),columns=X_train_rfe2.columns)\n",
    "ridge_coeff2 = ridge_coeff2.T\n",
    "ridge_coeff2.rename(columns={0: 'Ridge Co-Efficient'},inplace=True)\n",
    "ridge_coeff2.sort_values(by=['Ridge Co-Efficient'], ascending=False,inplace=True)\n",
    "ridge_coeff2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Top 20 features impacting the price of the property is stated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso\n",
    "For demonstration purposes, we try a Lasso Model as well to check it's overall perfromance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model with an arbitrary alpha to understand the value ranges\n",
    "lasso1 = Lasso(alpha=0.0001)        \n",
    "lasso1.fit(X_train_rfe2, y_train) \n",
    "\n",
    "y_test_pred = lasso1.predict(X_test_rfe2)\n",
    "print('The R2 Score of the model on the test dataset for 0.0001 alpha is',r2_score(y_test, y_test_pred))\n",
    "print('The MSE of the model on the test dataset for optimum alpha is', mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 75 features used in the Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builsing a Lasso Model with GridSearch CV to find the optimum alpha\n",
    "params = {'alpha': [0.00001, 0.00009, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009 ]}\n",
    "lasso = Lasso(random_state=100)\n",
    "\n",
    "# cross validation\n",
    "folds = 11\n",
    "model_cv = GridSearchCV(estimator = lasso, param_grid = params, scoring= 'r2', cv = folds, return_train_score=True, verbose = 1)            \n",
    "model_cv.fit(X_train_rfe2, y_train) \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title(\"R2 Score and Alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "alpha = cv_results['param_alpha'].loc[cv_results['mean_test_score'].idxmax()]\n",
    "print('The optimum alpha is',alpha)\n",
    "lasso_final2 = Lasso(alpha=alpha,random_state=100)\n",
    "lasso_final2.fit(X_train_rfe2,y_train)\n",
    "lasso_coef2 = lasso_final2.coef_\n",
    "y_test_pred = lasso_final2.predict(X_test_rfe2)\n",
    "print('The R2 Score of the model on the test dataset for optimum alpha is',r2_score(y_test, y_test_pred))\n",
    "print('The MSE of the model on the test dataset for optimum alpha is', mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaing the co-efficients of the model\n",
    "lasso_coeff2 = pd.DataFrame(np.atleast_2d(lasso_coef2),columns=X_train_rfe2.columns)\n",
    "lasso_coeff2 = lasso_coeff2.T\n",
    "lasso_coeff2.rename(columns={0: \"Lasso Co-Efficient\"},inplace=True)\n",
    "lasso_coeff2.sort_values(by=['Lasso Co-Efficient'], ascending=False,inplace=True)\n",
    "lasso_coeff2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 20 features of the final Lasso model is stated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Final Ridge Regression Model is as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_final2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Final Lasso Regression Model is as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_final2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to achieve an R2 score of 0.82 approx on both Ridge and Lasso Models. \n",
    "The follwing factors influence the house price the most as demosntrated by both the models:-\n",
    "- Total area in square foot\n",
    "- Total Garage Area\n",
    "- Total Rooms\n",
    "- Overall Condition\n",
    "- Lot Area\n",
    "- Centrally Air Conditioned\n",
    "- Total Porch Area (Open + Enclosed)\n",
    "- Kitchen Quality\n",
    "- Basement Quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
